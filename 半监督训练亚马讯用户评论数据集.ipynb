{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import joblib\n",
    "import nltk\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import SGD\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TITLE = \"reviews.title\"\n",
    "COLUMN_TEXT = \"reviews.text\"\n",
    "COLUMN_DO_RECOMMEND = \"reviews.doRecommend\"\n",
    "COLUMN_RATING = \"reviews.rating\"\n",
    "COLUMN_NUM_HELPFUL = \"reviews.numHelpful\"\n",
    "\n",
    "LABEL_UNKNOWN = -1\n",
    "LABEL_POS = 0\n",
    "LABEL_NEG = 1\n",
    "\n",
    "MAX_CONTENT_LENGTH = 1024\n",
    "\n",
    "MODEL_SAVE_PATH = \"model\" \n",
    "\n",
    "MODEL_PREPROCESSOR = \"preprocessor.model\"\n",
    "\n",
    "MODEL_KNN = \"knn.model\"\n",
    "MODEL_DECISION_TREE = \"dtc.model\"\n",
    "MODEL_NAIVE_BAYES = \"gnb.model\"\n",
    "MODEL_RANDOM_FOREST = \"rfc.model\"\n",
    "MODEL_LOGIC_REGRESSION = \"logic_regression.model\"\n",
    "MODEL_LINEAR_REGRESSION = \"linear_regression.model\"\n",
    "MODEL_SVM = \"svm.model\"\n",
    "MODEL_NN = \"nn.model\"\n",
    "MODEL_VOTE = \"vote.model\"\n",
    "\n",
    "FRAMEWORK_SKLEARN = \"sklearn\"\n",
    "FRAMEWORK_PYTORCH = \"pytorch\"\n",
    "\n",
    "DATASET_ROOT = \"data\"\n",
    "\n",
    "# 指定亚马讯数据集存储路径\n",
    "raw_data_file = os.path.join(DATASET_ROOT, \"Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
    "\n",
    "def get_label_desc(label):\n",
    "    if label == LABEL_POS:\n",
    "        return \"正面评价\"\n",
    "    elif label == LABEL_NEG:\n",
    "        return \"负面评价\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "def save_model(model, model_name, model_save_path, dev_fw_type=FRAMEWORK_SKLEARN, model_input_shape=None):\n",
    "    if model is None or model_name is None:\n",
    "        raise Exception(\"save model error, because model or model name is none\")\n",
    "        \n",
    "    if not os.path.exists(model_save_path):\n",
    "        print(f\"创建 {model_save_path}\")\n",
    "        os.makedirs(model_save_path)\n",
    "    \n",
    "    model_path = os.path.join(model_save_path, model_name)\n",
    "    print(f\"Saving \", model_path)\n",
    "    \n",
    "    if dev_fw_type == FRAMEWORK_PYTORCH:\n",
    "        if model_input_shape is None:\n",
    "            torch.save(model, model_path)\n",
    "        else:\n",
    "            torch_script_model = torch.jit.trace(model, torch.randn(model_input_shape))\n",
    "            torch.jit.save(torch_script_model, model_path)\n",
    "    else:\n",
    "        joblib.dump(model, model_path)\n",
    "        \n",
    "def load_model(model_path, dev_fw_type=FRAMEWORK_SKLEARN):\n",
    "    if dev_fw_type == FRAMEWORK_PYTORCH:\n",
    "        model = torch.load(model_path)\n",
    "    else:\n",
    "        model = joblib.load(filename=model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建词典并向量化文本(机器学习)\n",
    "UNK = \"unknown\"\n",
    "\n",
    "class PreProcessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def filter_stopwords_(self, X):\n",
    "        for x in X:\n",
    "            for col in range(2):\n",
    "                content = x[col]\n",
    "                origin_text_words = nltk.word_tokenize(content.strip().lower())\n",
    "                \n",
    "                new_texts = []\n",
    "                for word in origin_text_words:\n",
    "                    if word not in self.voc_model.stopwords:\n",
    "                        new_texts.append(word)\n",
    "                        \n",
    "                x[col] = \" \".join(new_texts)\n",
    "                \n",
    "        return X\n",
    "            \n",
    "    def deal_input(self, X):\n",
    "        \"\"\"\n",
    "        将title和text进行拼接\n",
    "        \"\"\"\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "        \n",
    "        sep_col = np.empty(shape=len(X)).astype(np.str_)\n",
    "        sep_col[:] = \" \"\n",
    "        \n",
    "        X_merge = np.char.add(X[:, 0], sep_col)\n",
    "        X_merge = np.char.add(X_merge, X[:, 1])\n",
    "        \n",
    "        return X_merge\n",
    "    \n",
    "    def construct_vocab(self, X):\n",
    "        X = self.deal_input(X)\n",
    "        \n",
    "        vocab, word2idx, idx2word, stopwords = Voc.construct_vocab(X)\n",
    "        self.voc_model = Voc(vocab, word2idx, idx2word, stopwords)\n",
    "\n",
    "        return self.voc_model\n",
    "    \n",
    "    def vectorize(self, X, y=None):\n",
    "        if X is None:\n",
    "            raise Exception(\"X is illegal\")\n",
    "        \n",
    "        return self._vectorize_data(X)\n",
    "    \n",
    "    def _vectorize_data(self, X):\n",
    "        vocab = self.voc_model.vocab\n",
    "        word2idx = self.voc_model.word2idx \n",
    "            \n",
    "        X_deal = self.deal_input(X)\n",
    "            \n",
    "        sentence_count, vocab_size = len(X_deal), len(vocab)\n",
    "\n",
    "        X_vec = np.zeros((sentence_count, vocab_size), dtype=np.int32)\n",
    "        for sentence_idx in range(sentence_count):\n",
    "            x_deal = X_deal[sentence_idx][:MAX_CONTENT_LENGTH]\n",
    "            words = nltk.word_tokenize(x_deal.strip().lower())\n",
    "            for word in words:\n",
    "                word_idx = word2idx[word] if word in vocab else word2idx[UNK]\n",
    "                X_vec[sentence_idx][word_idx] += 1\n",
    "            \n",
    "        X_vec = np.concatenate((X_vec, X[:, 2:].astype(np.float32)), axis=-1)\n",
    "        X_vec = X_vec.astype(np.int32)\n",
    "\n",
    "        return X_vec\n",
    "    \n",
    "    def transform_data(self, samples):\n",
    "        samples = self.filter_stopwords_(samples)\n",
    "        \n",
    "        content = self.vectorize(samples)\n",
    "        content = self.pca.transform(content)\n",
    "        \n",
    "        return content\n",
    "    \n",
    "    def init_PCA(self, X):\n",
    "        if \"pca\" in self.__dict__:\n",
    "            return self.pca\n",
    "        \n",
    "        pca = PCA()\n",
    "        pca.fit(X)\n",
    "\n",
    "        kl = KneeLocator(range(1, len(pca.explained_variance_) + 1), \n",
    "                         pca.explained_variance_, \n",
    "                         S=10.0, \n",
    "                         curve='convex', \n",
    "                         direction='decreasing')\n",
    "        \n",
    "        self.pca = PCA(n_components=kl.elbow, svd_solver=\"auto\")\n",
    "        X_pca = self.pca.fit_transform(X)\n",
    "\n",
    "        print(f\"本次降维保留了{X_pca.shape[1]}个特征，累积方差解释比例是{self.pca.explained_variance_ratio_.sum():.4}\")\n",
    "        \n",
    "        return self.pca\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, vocab, word2idx, idx2word, stopwords):\n",
    "        self.vocab = vocab\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.stopwords = stopwords\n",
    "\n",
    "    def construct_vocab(X):\n",
    "        vocab = {UNK}\n",
    "        word2idx = {}\n",
    "        idx2word = {}\n",
    "\n",
    "#         stopwords = [line.strip() for line in open(\"./stopwords_eng.txt\", \"r\", encoding=\"utf-8\").readlines()]\n",
    "        stopwords = []\n",
    "\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = X.tolist()\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            x_word_set = set(nltk.word_tokenize(X[i].strip().lower()))\n",
    "            count = 0\n",
    "            for word in x_word_set:\n",
    "                filter_word_set = set()\n",
    "                if word in stopwords:\n",
    "                    filter_word_set.add(word)\n",
    "                    continue\n",
    "                vocab = vocab.union(x_word_set - filter_word_set)\n",
    "\n",
    "        print(f\"Vocabulary has {len(vocab)} words\")\n",
    "\n",
    "        count = 0\n",
    "        for word in vocab:\n",
    "            word2idx[word] = count\n",
    "            idx2word[count] = word\n",
    "            count += 1\n",
    "\n",
    "        return vocab, word2idx, idx2word, stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonReviewTrainer:\n",
    "    \"\"\"\n",
    "    半监督训练器，将原始数据集拆分为正样本集、负样本集和缺失标签集，其中正样本1.5万条，负样本仅733条，缺失样本1.2万条，样本分布极不均衡，\n",
    "    故通过半监督学习，将每轮迭代训练好的投票模型，用于预测缺失样本集的1.2万条数据，然后将1.2万条数据用于训练下一迭代的模型。\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, raw_data_file):\n",
    "        # 从原始数据集挑选的候选字段\n",
    "        self.selected_columns = [COLUMN_TITLE, COLUMN_TEXT, COLUMN_RATING, COLUMN_DO_RECOMMEND]\n",
    "        \n",
    "        df = pd.read_csv(raw_data_file)[self.selected_columns]\n",
    "        \n",
    "        df_pos = df[df[COLUMN_DO_RECOMMEND] == True]\n",
    "        df_neg = df[df[COLUMN_DO_RECOMMEND] == False]\n",
    "        # 过滤缺失样本\n",
    "        self.df_null = df[df[COLUMN_DO_RECOMMEND].isna()]\n",
    "\n",
    "        print(f\"正样本数：{len(df_pos)}, 负样本数：{len(df_neg)}, 原始缺失样本数：{len(self.df_null)}\")\n",
    "        \n",
    "        # 合并正负样本为总样本集，从中挑选测试集\n",
    "        data = []\n",
    "        data.extend(df_pos.values.tolist())\n",
    "        data.extend(df_neg.values.tolist())\n",
    "        \n",
    "        data_index = []\n",
    "        data_index.extend(df_pos.index.tolist())\n",
    "        data_index.extend(df_neg.index.tolist())\n",
    "\n",
    "        data = np.array(data)\n",
    "        data_index = np.array(data_index).astype(np.int32)\n",
    "\n",
    "        X, y = data[:, :-1], data[:, -1]\n",
    "        # 切分数据集\n",
    "        _, X_test, _, y_test, _, X_index_test = train_test_split(X, y, data_index, test_size=.4, random_state=0, shuffle=True)\n",
    "        \n",
    "        # 保留专门的测试数据，不参与训练\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.y_test[self.y_test == \"True\"] = LABEL_POS\n",
    "        self.y_test[self.y_test == \"False\"] = LABEL_NEG\n",
    "        self.y_test = self.y_test.astype(np.int32)\n",
    "        \n",
    "        # 将测试集数据，从原始数据集中剔除\n",
    "        df = df.drop(X_index_test)\n",
    "        \n",
    "        print(f\"测试集：{len(self.X_test)}\")\n",
    "        \n",
    "        # 获取剔除测试本后的正负样本集合\n",
    "        self.df_pos = df[df[COLUMN_DO_RECOMMEND] == True]\n",
    "        self.df_neg = df[df[COLUMN_DO_RECOMMEND] == False]\n",
    "        \n",
    "        preprocessor_path = os.path.join(MODEL_SAVE_PATH, MODEL_PREPROCESSOR)\n",
    "        if not os.path.exists(preprocessor_path):\n",
    "            print(\"构建预处理器\")\n",
    "            self.preprocessor = PreProcessor()\n",
    "            \n",
    "            X_vocab = df[[COLUMN_TITLE, COLUMN_TEXT]].values.tolist()\n",
    "            self.preprocessor.construct_vocab(X_vocab)\n",
    "        else:\n",
    "            print(\"加载预处理器\")\n",
    "            self.preprocessor = load_model(model_path=preprocessor_path)\n",
    "            \n",
    "        print(f\"词表数：{len(self.preprocessor.voc_model.vocab)}\")\n",
    "        \n",
    "    def _cluster_null_sample(self, data_pos, data_neg, data_null):\n",
    "        \"\"\"\n",
    "        对无标签的样本进行聚类\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _prepare_fit(self):\n",
    "        self._load_model()\n",
    "        \n",
    "        df_null_pos = self.df_null[self.df_null[COLUMN_DO_RECOMMEND] == True]\n",
    "        df_null_neg = self.df_null[self.df_null[COLUMN_DO_RECOMMEND] == False]\n",
    "        \n",
    "        print(f\"从原始缺失样本中，提取{len(df_null_pos)}个正样本，{len(df_null_neg)}个负样本,\" \\\n",
    "              f\"{len(self.df_null) - len(df_null_pos) - len(df_null_neg)}个仍缺失\")\n",
    "        \n",
    "        data_null_pos = df_null_pos.values.tolist()\n",
    "        data_null_neg = df_null_neg.values.tolist()\n",
    "        \n",
    "        data_neg = self.df_neg.values.tolist()\n",
    "        data_pos = self.df_pos.values.tolist()\n",
    "                   \n",
    "        data_neg.extend(data_null_neg)\n",
    "        data_pos.extend(data_null_pos)\n",
    "                 \n",
    "        data_neg = np.array(data_neg)\n",
    "        data_pos = np.array(data_pos)\n",
    "        \n",
    "        # 随机采样正样本，使正负样本数量均衡\n",
    "        data_neg_count = len(data_neg)\n",
    "        data_pos_count = len(data_pos)\n",
    "        data_sample_count = data_neg_count if data_neg_count <= data_pos_count else data_pos_count\n",
    "        \n",
    "        data_neg_sample_idx = np.random.choice(range(data_neg_count), size=(data_sample_count,))\n",
    "        data_pos_sample_idx = np.random.choice(range(data_pos_count), size=(data_sample_count,))\n",
    "                 \n",
    "        data_neg = data_neg[data_neg_sample_idx]\n",
    "        data_pos = data_pos[data_pos_sample_idx]\n",
    "        \n",
    "        print(f\"调整采样后，正样本：{len(data_neg)}，负样本：{len(data_pos)}\")\n",
    "        \n",
    "        data = []\n",
    "        data.extend(data_neg)\n",
    "        data.extend(data_pos)\n",
    "        \n",
    "        data = np.array(data)\n",
    "        \n",
    "        X_train, y_train = data[:, :-1], data[:, -1]\n",
    "        \n",
    "        y_train[y_train == \"True\"] = LABEL_POS\n",
    "        y_train[y_train == \"False\"] = LABEL_NEG\n",
    "\n",
    "        y_train = y_train.astype(np.int32)\n",
    "        \n",
    "        X_null = np.array(self.df_null.values.tolist())\n",
    "        \n",
    "#         self._cluster_null_sample()\n",
    "    \n",
    "        X_train = self.preprocessor.filter_stopwords_(X_train)\n",
    "        self.X_test = self.preprocessor.filter_stopwords_(self.X_test)\n",
    "    \n",
    "        X_train_vec = self.preprocessor.vectorize(X_train, y_train)\n",
    "        self.X_test_vec = self.preprocessor.vectorize(self.X_test)\n",
    "        \n",
    "        pca = self.preprocessor.init_PCA(X_train_vec)\n",
    "        X_train_vec = pca.transform(X_train_vec)\n",
    "        self.X_test_vec = pca.transform(self.X_test_vec)\n",
    "\n",
    "        if \"X_null_vec\" not in locals():\n",
    "            X_null = self.preprocessor.filter_stopwords_(X_null)\n",
    "            self.X_null_vec = self.preprocessor.vectorize(X_null[:, :-1])\n",
    "            self.X_null_vec = pca.transform(self.X_null_vec)\n",
    "            \n",
    "        save_model(self.preprocessor, model_name=MODEL_PREPROCESSOR, model_save_path=MODEL_SAVE_PATH)\n",
    "        \n",
    "        return X_train_vec, y_train\n",
    "    \n",
    "    def fit(self, epochs=1):\n",
    "        for i in range(epochs):\n",
    "            print(f\"Epoch {i}: --------------------------------\")\n",
    "            X_train, y_train = self._prepare_fit()\n",
    "            \n",
    "            print(self.y_test)\n",
    "            # TODO: 增加KMeans\n",
    "            dtc = self._fit_dtc(X_train, self.X_test_vec, y_train, self.y_test)\n",
    "#             knn = self._fit_knn(X_train, self.X_test_vec, y_train, self.y_test)\n",
    "            gnb = self._fit_gnb(X_train, self.X_test_vec, y_train, self.y_test)\n",
    "            rfc = self._fit_rfc(X_train, self.X_test_vec, y_train, self.y_test)\n",
    "            lr = self._fit_lr(X_train, self.X_test_vec, y_train, self.y_test)\n",
    "            svc = self._fit_svc(X_train, self.X_test_vec, y_train, self.y_test)\n",
    "\n",
    "            estimators = [(\"dtc\", dtc), (\"gnb\", gnb), (\"rfc\", rfc), (\"logic\", lr), (\"svc\", svc)] # (\"knn\", knn), \n",
    "            self.vote = self._fit_vote(estimators, X_train, self.X_test_vec, y_train, self.y_test)\n",
    "            \n",
    "            y_null = self.predict(self.X_null_vec)\n",
    "            \n",
    "            del self.df_null[COLUMN_DO_RECOMMEND]\n",
    "            self.df_null[COLUMN_DO_RECOMMEND] = y_null.astype(bool)\n",
    "            \n",
    "#             dr_new = pd.DataFrame({COLUMN_DO_RECOMMEND:y_null.astype(bool)})\n",
    "#             self.df_null.update(dr_new)\n",
    "\n",
    "        print(\"训练完成\")\n",
    "        \n",
    "    def _fit_dtc(self, X_train, X_test, y_train, y_test):\n",
    "        self.dtc.fit(X_train, y_train)\n",
    "\n",
    "        dtc_train_score = self.dtc.score(X_train, y_train)\n",
    "        dtc_test_score = self.dtc.score(X_test, y_test)\n",
    "\n",
    "        save_model(self.dtc, MODEL_DECISION_TREE, MODEL_SAVE_PATH)\n",
    "        \n",
    "        print(f\"DecisionTreeClassifier：训练集分数：{dtc_train_score:.4}, 测试集分数：{dtc_test_score:.4}\")\n",
    "        \n",
    "        return self.dtc\n",
    "        \n",
    "    def _fit_knn(self, X_train, X_test, y_train, y_test):\n",
    "        self.knn.fit(X_train, y_train)\n",
    "\n",
    "        knn_train_score = self.knn.score(X_train, y_train)\n",
    "        knn_test_score = self.knn.score(X_test, y_test)\n",
    "\n",
    "        save_model(self.knn, MODEL_KNN, MODEL_SAVE_PATH)\n",
    "\n",
    "        print(f\"KNN：训练集分数：{knn_train_score:.4}, 测试集分数：{knn_test_score:.4}\")\n",
    "        \n",
    "        return self.knn\n",
    "        \n",
    "    def _fit_gnb(self, X_train, X_test, y_train, y_test):\n",
    "        self.gnb.fit(X_train, y_train)\n",
    "\n",
    "        gnb_train_score = self.gnb.score(X_train, y_train)\n",
    "        gnb_test_score = self.gnb.score(X_test, y_test)\n",
    "\n",
    "        print(f\"GaussianNB：训练集分数：{gnb_train_score:.4}, 测试集分数：{gnb_test_score:.4}\")\n",
    "\n",
    "        save_model(self.gnb, MODEL_NAIVE_BAYES, MODEL_SAVE_PATH)\n",
    "        \n",
    "        return self.gnb\n",
    "        \n",
    "    def _fit_rfc(self, X_train, X_test, y_train, y_test):\n",
    "        self.rfc.fit(X_train, y_train)\n",
    "\n",
    "        rfc_train_score = self.rfc.score(X_train, y_train)\n",
    "        rfc_test_score = self.rfc.score(X_test, y_test)\n",
    "\n",
    "        save_model(self.rfc, MODEL_RANDOM_FOREST, MODEL_SAVE_PATH)\n",
    "\n",
    "        print(f\"RandomForestClassifier：训练集分数：{rfc_train_score:.4}, 测试集分数：{rfc_test_score:.4}\")\n",
    "        \n",
    "        return self.rfc\n",
    "    \n",
    "    def _fit_lr(self, X_train, X_test, y_train, y_test):\n",
    "        self.lr.fit(X_train, y_train)\n",
    "\n",
    "        lr_train_score = self.lr.score(X_train, y_train)\n",
    "        lr_test_score = self.lr.score(X_test, y_test)\n",
    "\n",
    "        save_model(self.lr, MODEL_LOGIC_REGRESSION, MODEL_SAVE_PATH)\n",
    "        \n",
    "        print(f\"LogisticRegression：训练集分数：{lr_train_score:.4}, 测试集分数：{lr_test_score:.4}\")\n",
    "        \n",
    "        return self.lr\n",
    "        \n",
    "    def _fit_svc(self, X_train, X_test, y_train, y_test):\n",
    "        self.svc.probability = True\n",
    "        self.svc.fit(X_train, y_train)\n",
    "\n",
    "        svc_train_score = self.svc.score(X_train, y_train)\n",
    "        svc_test_score = self.svc.score(X_test, y_test)\n",
    "\n",
    "        save_model(self.svc, MODEL_SVM, MODEL_SAVE_PATH)\n",
    "\n",
    "        print(f\"SVC：训练集分数：{svc_train_score:.4}, 测试集分数：{svc_test_score:.4}\")\n",
    "        \n",
    "        return self.svc\n",
    "    \n",
    "    def _fit_vote(self, estimators, X_train, X_test, y_train, y_test):\n",
    "#         vote_hard = VotingClassifier(estimators=estimators, voting=\"hard\")\n",
    "        vote = VotingClassifier(estimators=estimators, \n",
    "                                voting=\"soft\", \n",
    "                                weights=[1, 0.8, 2, 1.5, 1]) # 1,\n",
    "        vote.fit(X_train, y_train)\n",
    "        \n",
    "        vote_train_score = vote.score(X_train, y_train)\n",
    "        vote_test_score = vote.score(X_test, y_test)\n",
    "\n",
    "        save_model(vote, MODEL_VOTE, MODEL_SAVE_PATH)\n",
    "\n",
    "        print(f\"VotingClassifier：训练集分数：{vote_train_score:.4}, 测试集分数：{vote_test_score:.4}\")\n",
    "        \n",
    "        return vote\n",
    "    \n",
    "    def _load_model(self):\n",
    "        dtc_model_path = os.path.join(MODEL_SAVE_PATH, MODEL_DECISION_TREE)\n",
    "        knn_model_path = os.path.join(MODEL_SAVE_PATH, MODEL_KNN)\n",
    "        gnb_model_path = os.path.join(MODEL_SAVE_PATH, MODEL_NAIVE_BAYES)\n",
    "        rfc_model_path = os.path.join(MODEL_SAVE_PATH, MODEL_RANDOM_FOREST)\n",
    "        lr_model_path = os.path.join(MODEL_SAVE_PATH, MODEL_LOGIC_REGRESSION)\n",
    "        svc_model_path = os.path.join(MODEL_SAVE_PATH, MODEL_SVM)\n",
    "\n",
    "        self.dtc = load_model(dtc_model_path) if os.path.exists(dtc_model_path) else DecisionTreeClassifier()\n",
    "        self.knn = load_model(knn_model_path) if os.path.exists(knn_model_path) else KNeighborsClassifier()\n",
    "        self.gnb = load_model(gnb_model_path) if os.path.exists(gnb_model_path) else GaussianNB()\n",
    "        self.rfc = load_model(rfc_model_path) if os.path.exists(rfc_model_path) else RandomForestClassifier(bootstrap=False, max_features=17, n_estimators=100)\n",
    "        self.lr = load_model(lr_model_path) if os.path.exists(lr_model_path) else LogisticRegression(max_iter=1000)\n",
    "        self.svc = load_model(svc_model_path) if os.path.exists(svc_model_path) else SVC()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.vote.predict(X=X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return (y_pred == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正样本数：15353, 负样本数：733, 原始缺失样本数：12246\n",
      "测试集：6435\n",
      "加载预处理器\n",
      "词表数：12157\n",
      "Epoch 0: --------------------------------\n",
      "从原始缺失样本中，提取0个正样本，0个负样本,12246个仍缺失\n",
      "调整采样后，正样本：460，负样本：460\n",
      "Saving  model\\preprocessor.model\n",
      "[0 0 0 ... 0 0 0]\n",
      "Saving  model\\dtc.model\n",
      "DecisionTreeClassifier：训练集分数：1.0, 测试集分数：0.8808\n",
      "GaussianNB：训练集分数：0.7326, 测试集分数：0.8676\n",
      "Saving  model\\gnb.model\n",
      "Saving  model\\rfc.model\n",
      "RandomForestClassifier：训练集分数：1.0, 测试集分数：0.931\n",
      "Saving  model\\logic_regression.model\n",
      "LogisticRegression：训练集分数：0.9326, 测试集分数：0.9136\n",
      "Saving  model\\svm.model\n",
      "SVC：训练集分数：0.9598, 测试集分数：0.9131\n",
      "Saving  model\\vote.model\n",
      "VotingClassifier：训练集分数：0.9924, 测试集分数：0.9324\n",
      "12246 0         True\n",
      "1         True\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "25884    False\n",
      "25885     True\n",
      "25886     True\n",
      "25887     True\n",
      "25888     True\n",
      "Name: reviews.doRecommend, Length: 12246, dtype: bool\n",
      "Epoch 1: --------------------------------\n",
      "从原始缺失样本中，提取2050个正样本，10196个负样本,0个仍缺失\n",
      "调整采样后，正样本：10656，负样本：10656\n",
      "Saving  model\\preprocessor.model\n",
      "[0 0 0 ... 0 0 0]\n",
      "Saving  model\\dtc.model\n",
      "DecisionTreeClassifier：训练集分数：1.0, 测试集分数：0.855\n",
      "GaussianNB：训练集分数：0.7055, 测试集分数：0.542\n",
      "Saving  model\\gnb.model\n",
      "Saving  model\\rfc.model\n",
      "RandomForestClassifier：训练集分数：1.0, 测试集分数：0.9082\n",
      "Saving  model\\logic_regression.model\n",
      "LogisticRegression：训练集分数：0.8668, 测试集分数：0.8037\n",
      "Saving  model\\svm.model\n",
      "SVC：训练集分数：0.9351, 测试集分数：0.8847\n",
      "Saving  model\\vote.model\n",
      "VotingClassifier：训练集分数：0.9983, 测试集分数：0.8943\n",
      "12246 0        False\n",
      "1        False\n",
      "2         True\n",
      "3         True\n",
      "4         True\n",
      "         ...  \n",
      "25884     True\n",
      "25885    False\n",
      "25886    False\n",
      "25887    False\n",
      "25888    False\n",
      "Name: reviews.doRecommend, Length: 12246, dtype: bool\n",
      "Epoch 2: --------------------------------\n",
      "从原始缺失样本中，提取9998个正样本，2248个负样本,0个仍缺失\n",
      "调整采样后，正样本：2708，负样本：2708\n",
      "Saving  model\\preprocessor.model\n",
      "[0 0 0 ... 0 0 0]\n",
      "Saving  model\\dtc.model\n",
      "DecisionTreeClassifier：训练集分数：1.0, 测试集分数：0.8664\n",
      "GaussianNB：训练集分数：0.7559, 测试集分数：0.8036\n",
      "Saving  model\\gnb.model\n",
      "Saving  model\\rfc.model\n",
      "RandomForestClassifier：训练集分数：1.0, 测试集分数：0.9442\n",
      "Saving  model\\logic_regression.model\n",
      "LogisticRegression：训练集分数：0.9112, 测试集分数：0.9152\n",
      "Saving  model\\svm.model\n",
      "SVC：训练集分数：0.9472, 测试集分数：0.9218\n",
      "Saving  model\\vote.model\n",
      "VotingClassifier：训练集分数：0.9926, 测试集分数：0.9313\n",
      "12246 0         True\n",
      "1         True\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "25884     True\n",
      "25885     True\n",
      "25886     True\n",
      "25887     True\n",
      "25888     True\n",
      "Name: reviews.doRecommend, Length: 12246, dtype: bool\n",
      "Epoch 3: --------------------------------\n",
      "从原始缺失样本中，提取2470个正样本，9776个负样本,0个仍缺失\n",
      "调整采样后，正样本：10236，负样本：10236\n",
      "Saving  model\\preprocessor.model\n",
      "[0 0 0 ... 0 0 0]\n",
      "Saving  model\\dtc.model\n",
      "DecisionTreeClassifier：训练集分数：1.0, 测试集分数：0.8623\n",
      "GaussianNB：训练集分数：0.7061, 测试集分数：0.5395\n",
      "Saving  model\\gnb.model\n",
      "Saving  model\\rfc.model\n",
      "RandomForestClassifier：训练集分数：1.0, 测试集分数：0.9175\n",
      "Saving  model\\logic_regression.model\n",
      "LogisticRegression：训练集分数：0.8618, 测试集分数：0.816\n",
      "Saving  model\\svm.model\n",
      "SVC：训练集分数：0.9321, 测试集分数：0.8922\n",
      "Saving  model\\vote.model\n",
      "VotingClassifier：训练集分数：0.9983, 测试集分数：0.8996\n",
      "12246 0        False\n",
      "1        False\n",
      "2         True\n",
      "3         True\n",
      "4         True\n",
      "         ...  \n",
      "25884    False\n",
      "25885    False\n",
      "25886    False\n",
      "25887    False\n",
      "25888    False\n",
      "Name: reviews.doRecommend, Length: 12246, dtype: bool\n",
      "Epoch 4: --------------------------------\n",
      "从原始缺失样本中，提取9620个正样本，2626个负样本,0个仍缺失\n",
      "调整采样后，正样本：3086，负样本：3086\n",
      "Saving  model\\preprocessor.model\n",
      "[0 0 0 ... 0 0 0]\n",
      "Saving  model\\dtc.model\n",
      "DecisionTreeClassifier：训练集分数：1.0, 测试集分数：0.8517\n",
      "GaussianNB：训练集分数：0.7471, 测试集分数：0.7927\n",
      "Saving  model\\gnb.model\n",
      "Saving  model\\rfc.model\n",
      "RandomForestClassifier：训练集分数：1.0, 测试集分数：0.9433\n",
      "Saving  model\\logic_regression.model\n",
      "LogisticRegression：训练集分数：0.8963, 测试集分数：0.9082\n",
      "Saving  model\\svm.model\n",
      "SVC：训练集分数：0.9412, 测试集分数：0.9091\n",
      "Saving  model\\vote.model\n",
      "VotingClassifier：训练集分数：0.9947, 测试集分数：0.9248\n",
      "12246 0         True\n",
      "1         True\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "25884     True\n",
      "25885     True\n",
      "25886     True\n",
      "25887     True\n",
      "25888     True\n",
      "Name: reviews.doRecommend, Length: 12246, dtype: bool\n",
      "训练完成\n"
     ]
    }
   ],
   "source": [
    "art = AmazonReviewTrainer(raw_data_file=raw_data_file)\n",
    "art.fit(epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测准确率：0.86\n",
      "['good pad' 'this is good good pad !' '3'] ， 负面评价\n",
      "['bad pad' 'too bad pad !' '3'] ， 负面评价\n",
      "['first tablet . lots of possibilities .'\n",
      " 'great size , easy to carry for traveling . need to spend more time looking into apps for contact manegement , interactive calenders and most important , music storage and '\n",
      " '5'] ， 正面评价\n",
      "['acceptable for the price'\n",
      " \"love everything about the unit except that it gets hot when used for 10 to 15 minutes . hope it does n't burn or explode .\"\n",
      " '2'] ， 负面评价\n",
      "['it was average'\n",
      " 'purchased for my kids but it was hard to navigate and ended up with purchasing an ipad'\n",
      " '2'] ， 负面评价\n",
      "['works as advertised'\n",
      " 'this tablet was purchased for my son . it does exactly what i want it to do which is play games and surf the web , namely youtube . great value .'\n",
      " '5'] ， 正面评价\n",
      "['its ok for the price'\n",
      " 'i bought this on black friday , simply because it was dirt cheap . it works ok but kinda slow .'\n",
      " '2'] ， 负面评价\n"
     ]
    }
   ],
   "source": [
    "preprocessor_model_path =os.path.join(MODEL_SAVE_PATH, MODEL_PREPROCESSOR)\n",
    "preprocessor = load_model(preprocessor_model_path)\n",
    "\n",
    "model_path = os.path.join(MODEL_SAVE_PATH, MODEL_VOTE)\n",
    "vote = load_model(model_path=model_path)\n",
    "\n",
    "sample1 = [\"Good pad\", \"This is good good pad!\", 3]\n",
    "sample2 = [\"Bad pad\", \"Too bad pad!\", 3]\n",
    "sample3 = [\"First Tablet. Lots of possibilities.\",\n",
    "           \"Great size, easy to carry for traveling. Need to spend more time Looking into apps for contact manegement, interactive calenders and most important, music storage and use.\",\n",
    "           5\n",
    "          ]\n",
    "sample4 = [\"Acceptable for the price\",\n",
    "           \"Love everything about the unit except that it gets hot when used for 10 to 15 minutes. Hope it doesn't burn or explode.\",\n",
    "           2\n",
    "          ]\n",
    "sample5 = [\"It was average\",\n",
    "           \"Purchased for my kids but it was hard to navigate and ended up with purchasing an iPad\",\n",
    "           2\n",
    "          ]\n",
    "sample6 = [\"Works as advertised\",\n",
    "           \"This tablet was purchased for my son. It does exactly what i want it to do which is play games and surf the web, namely YouTube. Great value.\",\n",
    "           5\n",
    "          ]\n",
    "sample7 = [\"Its ok for the price\",\n",
    "           \"I bought this on Black Friday, simply because it was dirt cheap. It works ok but kinda slow.\",\n",
    "           2\n",
    "          ]\n",
    "\n",
    "samples = np.array([sample1, sample2, sample3, sample4, sample5, sample6, sample7])\n",
    "samples_label = np.array([0, 1, 0, 1, 1, 0, 1]).astype(np.int32)\n",
    "\n",
    "content = preprocessor.transform_data(samples)\n",
    "predict_result = vote.predict(content)\n",
    "\n",
    "print(f\"预测准确率：{(samples_label == predict_result).mean():.2}\")\n",
    "\n",
    "for content, pred in zip(samples, predict_result):\n",
    "    print(content, \"，\", get_label_desc(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
